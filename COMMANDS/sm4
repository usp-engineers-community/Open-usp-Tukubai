#!/usr/bin/env python
#coding: utf-8
#
# sm4 小計/中計挿入ツール（Open usp Tukubai版）
# 
# designed by Nobuaki Tounaka
# written  by Masatomo Togashi
#
# The MIT License
#
# Copyright (C) 2020 Universal Shell Programming Laboratory
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

from __future__ import print_function

_usage = "sm4 [+h] <k1> <k2> <d1> <d2> <s1> <s2> <file>"
_version = "Tue Oct 20 15:17:47 JST 2020"
_code = "Open usp Tukubai (LINUX+FREEBSD/PYTHON2.4/UTF-8)"
_keypat = r'\d+|NF(-\d+)?$'
wide_class = ["W","F","A"]	# 全角文字クラス

DUMMY_CHAR = '@'

import re
import os
import sys
from decimal import Decimal
import unicodedata

# 濁音と半濁音のNFD表記でNFC表記もできるもの→NFDtoNFC変換でNFCに統一する
_comb_pat=r"(((う|か|き|く|け|こ|さ|し|す|せ|そ|た|ち|つ|て|と|は|ひ|ふ|へ|ほ|ウ|カ|キ|ク|ケ|コ|サ|シ|ス|セ|ソ|タ|チ|ツ|テ|ト|ハ|ヒ|フ|ヘ|ホ|ワ|ヰ|ヱ|ヲ)゙)|((は|ひ|ふ|へ|ほ|ハ|ヒ|フ|ヘ|ホ)゚))+"

def error(msg, *arg):
	print('Error[sm4] :', msg % arg, file=sys.stderr)
	sys.exit(1)

def usage():
	print("Usage   :", _usage, file=sys.stderr)
	print("Version :", _version, file=sys.stderr)
	print("         ", _code, file=sys.stderr)
	sys.exit(1)

class FieldLine:
	def __init__(self, line, allow_z = False):
		self.__allow_zero = allow_z
		self.__fields = [ line ]
		self.__fields += [ x for x in line.split(' ') if x ]

	def size(self):
		return len(self.__fields) - 1

	def getFieldNum(self, key):
		if type(key) == type(0):
			return key
		if re.match(r'\d+$', key):
			key = int(key)
		elif key == 'NF':
			key = self.size()
		else:
			key = self.size() - int(key[3:])
			if key <= 0:
				error("NF-x の x が大きすぎます。")
		if key < 0:
			error("フィールド番号が負です。")
		if key == 0 and not self.__allow_zero:
			error("フィールド番号が０です。")
		if key > self.size():
			error("フィールド番号が大きすぎます。")
		return key

	def getField(self, s, e = None):
		s = self.getFieldNum(s)
		if e == None:
			e = s
		else:
			e = self.getFieldNum(e)
		if s <= e:
			return ' '.join(self.__fields[s : e + 1])
		else:
			t = self.__fields[e : s + 1]
			t.reverse()
			return ' '.join(t)

#
# unicode 変換
#
def to_unicode(s):
	if Python3(): return s
	try:
		return unicode(s, 'utf_8')
	except:
		error("不当なマルチバイト文字が含まれています。")

#
# 代用対前半部の判定
#
def isHighSurrogate(cp):
	if 0xd800 <= cp and cp <= 0xdbff: return True
	else:                             return False

#
# 代用対後半部の判定
#
def isLowSurrogate(cp):
	if 0xdc00 <= cp and cp <= 0xdfff: return True
	else:                             return False

#
# UCS2の判定
#
def isUCS2():
	if sys.maxunicode==0xFFFF: return True
	else:                      return False

#
# unicodedata.east_asian_width()「東アジアの文字幅」の修正版
#
def east_asian_width(c):
	if len(c)>=2: return unicodedata.east_asian_width(c)	# UCS2で代用対が与えられたとき
	# unicodedata.east_asian_width()は半角オーバ－ライン「‾」（U+203e）に対して
	# A（Ambiguous; 曖昧=ギリシャ文字/ロシア文字と同様に全角扱いされる）を返すので
	# Na（Narrow; 狭=半角英数記号）に準ずるものと修正する
	elif ord(c)==0x203e: return 'Na'
	else:                return unicodedata.east_asian_width(c)
#
# 代用対前半部の判定
#
def isHighSurrogate(cp):
	if 0xd800 <= cp and cp <= 0xdbff: return True
	else:                             return False

#
# 代用対後半部の判定
#
def isLowSurrogate(cp):
	if 0xdc00 <= cp and cp <= 0xdfff: return True
	else:                             return False

#
# UCS2の判定
#
def isUCS2():
	if sys.maxunicode==0xFFFF: return True
	else:                      return False

#
# unicodedata.east_asian_width()「東アジアの文字幅」の修正版
#
def east_asian_width(c):
	if len(c)>=2: return unicodedata.east_asian_width(c)	# UCS2で代用対が与えられたとき
	# unicodedata.east_asian_width()は半角オーバ－ライン「‾」（U+203e）に対して
	# A（Ambiguous; 曖昧=ギリシャ文字/ロシア文字と同様に全角扱いされる）を返すので
	# Na（Narrow; 狭=半角英数記号）に準ずるものと修正する
	elif ord(c)==0x203e: return 'Na'
	else:                return unicodedata.east_asian_width(c)

#
# 拡張文字の標準文字部分について符号位置（code point）の取得
#
def xord(xchar):
	if len(xchar)>1:	# UCS2で代用対の場合 xcharは HighSurrogate+LowSurrogateの2文字分ある
		cp = 0x10000 + (ord(xchar[0]) - 0xD800) * 0x400 + (ord(xchar[1]) - 0xDC00);	# 代用対をdecodeする
	else:
		cp = ord(xchar)
	return cp

#
# 半角判定
#
def isHalfWidth(c):
	# 文字のEast_Asian_Width特性検査でFまたはWまたはAならば
	# F/W/A = Wide（全角英数記号） Full（漢字 ひらがな 全角カタカナ） Ambiguous（ロシア文字 ギリシャ文字）
	if east_asian_width(c) in wide_class: return False	# 全角
	else:                                 return True	# それ以外は半角

#
# 合成可能文字の判定
#
def isCombiningDiacriticalMark(cp):
	# unicodeにおける合成可能文字のブロック内か？
		# 0x3099 0x309a	仮名文字の合成可能濁点と合成可能半濁点
		# 0x0300-0x036F	ダイアクリティカルマーク（合成可能）
		# 0x1AB0-0x1AFF	ダイアクリティカルマーク（合成可能）拡張
		# 0x1DC0-0x1DFF	ダイアクリティカルマーク（合成可能）補助
		# 0x20D0-0x20FF	記号用ダイアクリティカルマーク（合成可能）
		# 0xFE20-0xFE2F	半記号（合成可能）
	if cp == 0x3099 or cp == 0x309a or \
		0x0300<=cp and cp <=0x036F or \
		0x1AB0<=cp and cp <=0x1AFF or \
		0x1DC0<=cp and cp <=0x1DFF or \
		0x20D0<=cp and cp <=0x20FF or \
		0xFE20<=cp and cp <=0xFE2F:
		return True
	else:	return False

#
# 異体字選択子（vaiation selector）の判定
#
def isVariationSelector(cp):
	# unicodeにおける異体字選択子のブロック内か？
		# 0xFE00-0xFE0F	Variation Selectors Supplement	字形選択子補助（SVS用）
		# 0xE0100-0xE01EF	Variation Selectors	字形選択子（IVS用）
	if  0xFE00<=cp  and cp <=0xFE0F or \
		0xE0100<=cp and cp <=0xE01EF:
		return True
	else:	return False

#
# 文字列の表示幅
#
def strwidth(s):
	wid = 0	# 表示幅の初期化
	s=string2list(to_unicode(s))
	# sは拡張文字列となった
	for xchar in s:
		if isHalfWidth(xchar[0]):	wid+=1	# 半角なら+1
		else:	wid+=2	# 全角なら+2
	return wid

#
# 文字列の分解
#
# 文字列を拡張文字の列に変換する	1文字が複数の符号位置であらわされている場合（代用対/結合文字/IVS/SVS）への対応
# 	分解結果はリストとなり各要素（拡張文字）は
# 		UCS2のときはリスト
# 			[ 通常文字または文字列としての代用対 , 結合文字または異体字選択子（2バイトまたは代用対）または空文字 ]
# 		UCS4のときは文字列
# 			文字列（通常文字に結合文字または異体字選択子が付くことがある）
def string2list(s):
	StringList=[]
	if isUCS2():
		surrogate_pair=False	# UCS2では代用対（surrogate pair）がありうる
		prevchar=""
		for c in s:
			cp=ord(c)	# code point			
			# 代用対（[D800～DBFF]+[DC00～DFFF]のペア）の存在を考慮する
			if not surrogate_pair:	# 代用対の処理中でなければ
				if isHighSurrogate(cp):	# 代用対の前半部なら
					surrogate_pair=True	# surrogate pair starts
					HighSurrogate=c
					HighSurrogateCp=cp
					continue
				if isLowSurrogate(cp):	error("代用対の構成が無効です。")	# 代用対の後半部が単独で現れた
				elif isCombiningDiacriticalMark(cp):	# 合成可能文字なら
					if prevchar=="":	error("結合文字列の構成が無効です。")	# 空文字の次に合成可能文字が現われた
					StringList.append([prevchar,c])	# 先行文字と合成可能文字の組を追加（合成可能文字は第0面のみにある）
					prevchar=""
				elif isVariationSelector(cp):	# 異体字選択子なら
					if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
					StringList.append([prevchar,c])	# 先行文字とSVS用異体字選択子（2バイト）の組を追加
					prevchar=""
				else:	# 次となる普通の文字がきたら先行文字を単独で追加
					if prevchar!="":
						StringList.append([prevchar,""])	# 先行文字と空文字の組を追加
					prevchar=c	# 先行文字とする
			elif isLowSurrogate(cp):	# 代用対の処理中に代用対の後半部がきたら代用対の完成
				surrogate_pair=False	# surrogate pair ends
				sp=HighSurrogate+c	# 代用対を作る
				uni = 0x10000 + (HighSurrogateCp - 0xD800) * 0x400 + (cp - 0xDC00);	# 代用対をdecodeする
				if isVariationSelector(uni):	# 代用対が異体字選択子なら
					if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
					StringList.append([prevchar,sp])	# 先行文字とIVS用異体字選択子（4バイト）の組を追加
					prevchar=""
				else:	# 先行文字があって次に文字としての代用対が来た
					if prevchar!="":
						StringList.append([prevchar,""])	# 先行文字と空文字の組を追加
					prevchar=sp	# 代用対を先行文字とする
			else:	error("代用対の構成が無効です。")	# 代用対の前半部の次に代用対後半部以外が現われた
		if surrogate_pair: 	error("代用対の構成が無効です。")	# 代用対の前半部で文字列の終端に達した
		if prevchar!="":
			StringList.append([prevchar,""])	# 最後の先行文字と空文字の組を追加
	else:	# UCS4
		prevchar=""
		for c in s:
			cp=ord(c)	# code point
			if isCombiningDiacriticalMark(cp):	# 合成可能文字なら
				if prevchar=="":	error("結合文字列の構成が無効です。")	# 空文字の次に合成可能文字が現われた
				StringList.append(prevchar+c)	# 先行文字と合成可能文字の列を追加
				prevchar=""
			elif isVariationSelector(cp):	# 異体字選択子なら
				if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
				StringList.append(prevchar+c)	# 先行文字とIVS用異体字選択子（4バイト）の列を追加
				prevchar=""
			else:
				if prevchar!="":	StringList.append(prevchar)	# 次となる普通の文字がきたら先行文字を単独で追加
				prevchar=c	# 先行文字とする
		if prevchar!="":
			StringList.append(prevchar)	# 最後の先行文字を追加
	return StringList

#
# 入力ファイルオープン
#
def open_file(n):
	if n >= len(sys.argv):	filename = '-'
	else:
		filename = sys.argv[n]
	if filename == '-':	filename = '/dev/fd/0'	# sys.stdinをファイルディスクリプターで表記する
	if Python3():	mode='r'
	else:	mode='rU'	# Python2ではmodeがrUのときPython3と同様に読み込み時に各種改行記号がLF（\n）に統一される
	try:
		file = open(filename, mode)
	except:
		if filename=='/dev/fd/0':
			error("標準入力ファイルをオープンできません。")
		else:
			error("ファイル '%s' をオープンできません。", filename)
	return file

# 改行符号（\r\n）の削除関数
def rm_eol(line):
	return line.rstrip("\r\n")	# 改行記号としてCRLF('\r\n')/CR('\r')/LF('\n')のすべてに対応する

# BOMの取得関数
def get_BOM():
	if Python3():	return chr(int("FEFF",16))	# U+FEFFはBOMのUnicode符号位置
	else:			return "\xEF\xBB\xBF"	# BOMは「EF BB BF」の3バイト

# BOMの削除関数
def rm_BOM(line):
	global firstline
	if not firstline: return line
	firstline=False
	if line.startswith(get_BOM()):	line=line[len(get_BOM()):]	# 行頭にBOMがあったらBOMを削除する
	return line

# ファイル入力行の前処理
def preproc_line(line):
	line=rm_eol(line)	# 行末の改行記号を削除する
	line=rm_BOM(line)	# ファイル先頭行の行頭にBOMがあったらこれを削除する
	return line

# Python3か判定する
def Python3():
	if sys.version_info >= (3, 0):
		return True
	else:
		return False

#
# utf8 変換
#
def to_utf8(s):
	try:
		return s.encode('utf-8')
	except:
		error("内部エラー UTF8への変換に失敗しました。")

#
# NFDtoNFC()のre.sub()から指定patternがみつかるごとに呼ばれるのでNFD/NFC変換をして返す
# 置換対象パターンはNFD文字:全角ひらがな/全角カタカナの清音に結合用濁点/結合用半濁点を連接したもの
# 置換先文字はNFC文字:全角ひらがな/全角カタカナの濁音/半濁音
#
def replace(matchobj):
	if Python3():	return unicodedata.normalize('NFC',matchobj.group(0))
	else:	return to_utf8(unicodedata.normalize('NFC',to_unicode(matchobj.group(0))))	# Python2ではutf8→unicdoe→utf8の変換をする

#
# 全角ひらがな/全角カタカナの濁音/半濁音のNFC化
#
def NFDtoNFC(str):
	# 全角ひらがな/全角カタカナの濁音/半濁音をNFCで統一して返す
	return re.sub(pattern,replace,str)

#
# フィールド値の取得
#
def getval(line, n):
	if re.match(r'(\+|-)?(\d+\.?|\d*\.\d+)$', line.getField(n)):
		return Decimal(line.getField(n))
	else:
		error("数値変換できません。")

#
# メイン関数
#
if __name__ == '__main__':

	if len(sys.argv) < 7:
		usage()

	#
	# NFD文字（清音+結合用濁点/結合用半濁点）検出のための正規表現パターンを準備
	#
	pattern=re.compile(_comb_pat)

	#
	# +h
	#
	if sys.argv[1] == '+h':
		header = True
		del sys.argv[1]
		if len(sys.argv) < 7:
			usage()
	else:
		header = False

	#
	# key=<key>
	#
	k1 = sys.argv[1]
	k2 = sys.argv[2]
	d1 = sys.argv[3]
	d2 = sys.argv[4]
	s1 = sys.argv[5]
	s2 = sys.argv[6]
	p = re.compile(_keypat)
	if not (p.match(k1) and p.match(k2) and p.match(s1) and p.match(s2)):
		usage()

	file = open_file(7)

	firstline=True
	#
	# ヘッダー出力
	#
	if header:
		line = file.readline()
		if not line:
			sys.exit(0)
		line=preproc_line(line)	# 入力行の前処理
		print(line)

	#
	# １行入力
	#
	line = file.readline()
	if not line:
		sys.exit(0)
	line=preproc_line(line)	# 入力行の前処理
	line = FieldLine(line)
	k1 = line.getFieldNum(k1)
	k2 = line.getFieldNum(k2)
	if d1.lower()=="x" and d2.lower()=="x":	# d1/d2が"x"なら値を-k1/-k2にする
		d1=-k1
		d2=-k2
	else:
		d1 = line.getFieldNum(d1)
		d2 = line.getFieldNum(d2)
	s1 = line.getFieldNum(s1)
	s2 = line.getFieldNum(s2)
	# 降順を昇順化
	if k1 > k2:	k1,k2=k2,k1
	if d1 > d2:	d1,d2=d2,d1
	if s1 > s2:	s1,s2=s2,s1
	if k2 > abs(d1) or abs(d2) > s1:
		usage()

	#
	# ダミー文字列の生成
	#
	# d1/d2に"x"が指定されているときは副キーではなく主キーフィールドに対応したdummyを作る
	dummy = ''
	for i in range(abs(d1), abs(d2)):
		dummy += DUMMY_CHAR * strwidth(line.getField(i)) + ' '
	dummy += DUMMY_CHAR * strwidth(line.getField(abs(d2)))

	#
	# 合計の初期化
	#
	sum = [ 0 for i in range(s2 + 1) ]
	if not DUMMY_CHAR in line.getField(abs(d1), abs(d2)):
		for i in range(s1, s2 + 1):
			sum[i] = getval(line, i)
		if (k1):
			key = NFDtoNFC(line.getField(k1, k2))	# キーフィールド値はNFC正規化する
	print(line.getField(0))	# 行全体を出力する

	#
	# メインループ
	#
	firstline=True
	for line in file:
		line=preproc_line(line)	# 入力行の前処理
		line = FieldLine(line)
		if DUMMY_CHAR in line.getField(abs(d1), abs(d2)):
			print(line.getField(0))
			continue
		if NFDtoNFC(line.getField(k1, k2)) == key:	# キーフィールド値はNFC正規化する
			for i in range(s1, s2 + 1):
				sum[i] += getval(line, i)
			print(line.getField(0))
			continue
		# 新しいkeyが出現した
		if d1>0:	# d1/d2に数値が指定されているとき
			print(key, dummy, end=' ')	# これまでのkeyとdummy文字列を出力
		else:	# d1/d2に"x"が指定されているとき
			print(dummy, end=' ')	# keyに対応したdummy文字列を出力
		for i in range(s1, s2):
			print(sum[i], end=' ')
		print(sum[s2])
		for i in range(s1, s2 + 1):
			sum[i] = getval(line, i)
		key = NFDtoNFC(line.getField(k1, k2))	# キーフィールド値はNFC正規化する
		print(line.getField(0))	# 行全体を出力する

	#
	# 残り合計の出力
	#
	if d1>0:	# d1/d2に数値が指定されているとき
		print(key, dummy, end=' ')	# これまでのkeyとdummy文字列を出力
	else:	# d1/d2に"x"が指定されている
		print(dummy, end=' ')	# keyに対応したdummy文字列を出力
	for i in range(s1, s2):
		print(sum[i], end=' ')
	print(sum[s2])

	sys.exit(0)
