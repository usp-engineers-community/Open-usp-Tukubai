#!/usr/bin/env python
#coding: utf-8
#
# check_attr_name name 形式の属性チェック（Open usp Tukubai版）
# 
# designed by Nobuaki Tounaka
# written  by Masatomo Togashi
#
# The MIT License
#
# Copyright (C) 2021 Universal Shell Programming Laboratory
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

from __future__ import print_function

_usage = "check_attr_name <check_file> <name_file>"
_option = "--through <string>"
_option1 = "--ngword <ng_file>"
_attribute = "n N (０以上整数)"
_attribute1 = "s S (符号つき整数)"
_attribute2 = "f F (小数)"
_attribute3 = "v V (符号つき小数)"
_attribute4 = "e E (英字)"
_attribute5 = "a A (アスキー文字)"
_attribute6 = "b B (英数字)"
_attribute7 = "h H (半角文字)"
_attribute8 = "z Z (全角文字)"
_attribute9 = "k K (全角カタカナ)"
_attribute10 = "x X (文字)"
_attribute11 = "c C (チェックディジット)"
_attribute12 = "o O (英大文字)"
_attribute13 = "j J (住所=全角+半角英数記号)"
_version = "Mon Dec 20 21:02:03 JST 2021"
_code = "Open usp Tukubai (LINUX+FREEBSD/PYTHON2.4/UTF-8)"
wide_class = ["W","F","A"]	# 全角文字クラス

# 濁音と半濁音のNFD表記でNFC表記もできるもの→NFDtoNFC変換でNFCに統一する
_comb_pat=r"(((う|か|き|く|け|こ|さ|し|す|せ|そ|た|ち|つ|て|と|は|ひ|ふ|へ|ほ|ウ|カ|キ|ク|ケ|コ|サ|シ|ス|セ|ソ|タ|チ|ツ|テ|ト|ハ|ヒ|フ|ヘ|ホ|ワ|ヰ|ヱ|ヲ)゙)|((は|ひ|ふ|へ|ほ|ハ|ヒ|フ|ヘ|ホ)゚))+"

import re
import os
import sys
import unicodedata

def error(msg, *arg):
	print('Error[check_attr_name] :', msg % arg, file=sys.stderr)
	sys.exit(1)

def usage():
	print("Usage    :", _usage, file=sys.stderr)
	print("Option   :", _option, file=sys.stderr)
	print("          ", _option1, file=sys.stderr)
	print("Attribute:", _attribute, file=sys.stderr)
	print("          ", _attribute1, file=sys.stderr)
	print("          ", _attribute2, file=sys.stderr)
	print("          ", _attribute3, file=sys.stderr)
	print("          ", _attribute4, file=sys.stderr)
	print("          ", _attribute5, file=sys.stderr)
	print("          ", _attribute6, file=sys.stderr)
	print("          ", _attribute7, file=sys.stderr)
	print("          ", _attribute8, file=sys.stderr)
	print("          ", _attribute9, file=sys.stderr)
	print("          ", _attribute10, file=sys.stderr)
	print("          ", _attribute11, file=sys.stderr)
	print("          ", _attribute12, file=sys.stderr)
	print("          ", _attribute13, file=sys.stderr)
	print("Version  :", _version, file=sys.stderr)
	print("          ", _code, file=sys.stderr)
	sys.exit(1)

#
# 入力ファイルオープン
#
def open_file(n):
	if type(n) == type(0):	# ファイルがコマンドパラメータの位置で指定されているなら
		if n >= len(sys.argv):	# ファイル名省略時
			n = '-'	# sys.stdinを仮定する
		else:
			n = sys.argv[n]	# 指定位置のコマンドパラメータをとる
	if n == '-':	# '-'が指定されているとき
		n = '/dev/fd/0'	# sys.stdinをファイルディスクリプターで表記する
	if Python3():
		mode='r'
	else:
		mode='rU'	# Python2ではmodeがrUのときPython3と同様に読み込み時に各種改行記号がLF（\n）に統一される
	# 標準入力も含めてopen()で開く
	try:
		file = open(n, mode)
	except:
		error("ファイル '%s' をオープンできません。", n)
	return file

#
# unicode 変換
#
def to_unicode(s):
	if type(s)==type(U""): return s	# 入力文字列がUnicode文字列のとき
	try:
		return unicode(s, 'utf_8')
	except:
		error("不当なマルチバイト文字が含まれています。")

#
# 文字列にngword内の文字が含まれているか検査する（ふたつの文字列の交差判定）
#
def checkNgword(s,Xngword):
	if len(Xngword)==0: return False	# Xngwordの指定がなかったときはngword判定にはひっかからない
	# sとXngwordは拡張文字列に変換済みで属性リストもある（形式は(拡張文字,属性)のtupleのlist）
	for i,c in enumerate(s):	# cは拡張文字
		for j,ng in enumerate(Xngword):	# ngは拡張文字
			if XcharMatch(c,ng):	# sのi番目とXngwordのj番目が一致したら
				return True	# ngword判定でひっかかった
	return False	# 対象文字列にはngwordで指定された文字はみつからなかった

#
# 代用対前半部の判定
#
def isHighSurrogate(cp):
	if 0xd800 <= cp and cp <= 0xdbff: return True
	else:                             return False

#
# 代用対後半部の判定
#
def isLowSurrogate(cp):
	if 0xdc00 <= cp and cp <= 0xdfff: return True
	else:                             return False

#
# UCS2の判定
#
def isUCS2():
	if sys.maxunicode==0xFFFF: return True
	else:                      return False

#
# unicodedata.east_asian_width()「東アジアの文字幅」の修正版
#
def east_asian_width(c):
	if len(c)>=2: return unicodedata.east_asian_width(c)	# UCS2で代用対が与えられたとき
	# unicodedata.east_asian_width()は半角オーバ－ライン「‾」（U+203e）に対して
	# A（Ambiguous; 曖昧=ギリシャ文字/ロシア文字と同様に全角扱いされる）を返すので
	# Na（Narrow; 狭=半角英数記号）に準ずるものと修正する
	elif ord(c)==0x203e: return 'Na'
	else:                return unicodedata.east_asian_width(c)

#
# 拡張文字の標準文字部分について符号位置（code point）の取得
#
def xord(xchar):
	# xcharには拡張文字の標準文字部分が与えられている
	if len(xchar)>1:	# UCS2で代用対の場合 xcharは HighSurrogate+LowSurrogateの2文字分ある
		cp = 0x10000 + (ord(xchar[0]) - 0xD800) * 0x400 + (ord(xchar[1]) - 0xDC00);	# 代用対をdecodeする
	else:
		cp = ord(xchar)	# UCS4では標準文字部分は1文字
	return cp

#
# 半角判定
#
def isHalfWidth(c):
	# 文字のEast_Asian_Width特性検査でFまたはWまたはAならば
	# F/W/A = Wide（全角英数記号） Full（漢字 ひらがな 全角カタカナ） Ambiguous（ロシア文字 ギリシャ文字）
	if east_asian_width(c) in wide_class: return False	# 全角
	else:                                 return True	# それ以外は半角

#
# 合成可能文字の判定
#
def isCombiningDiacriticalMark(cp):
	# unicodeにおける合成可能文字のブロック内か？
		# 0x3099 0x309a	仮名文字の合成可能濁点と合成可能半濁点
		# 0x0300-0x036F	ダイアクリティカルマーク（合成可能）
		# 0x1AB0-0x1AFF	ダイアクリティカルマーク（合成可能）拡張
		# 0x1DC0-0x1DFF	ダイアクリティカルマーク（合成可能）補助
		# 0x20D0-0x20FF	記号用ダイアクリティカルマーク（合成可能）
		# 0xFE20-0xFE2F	半記号（合成可能）
	if cp == 0x3099 or cp == 0x309a or \
		0x0300<=cp and cp <=0x036F or \
		0x1AB0<=cp and cp <=0x1AFF or \
		0x1DC0<=cp and cp <=0x1DFF or \
		0x20D0<=cp and cp <=0x20FF or \
		0xFE20<=cp and cp <=0xFE2F:
		return True
	else:	return False

#
# 異体字選択子（vaiation selector）の判定
#
def isVariationSelector(cp):
	# unicodeにおける異体字選択子のブロック内か？
		# 0xFE00-0xFE0F	Variation Selectors Supplement	字形選択子補助（SVS用）
		# 0xE0100-0xE01EF	Variation Selectors	字形選択子（IVS用）
	if  0xFE00<=cp  and cp <=0xFE0F or \
		0xE0100<=cp and cp <=0xE01EF:
		return True
	else:	return False

#
# 文字列の表示幅
#
def strwidth_u(s):
	wid = 0	# 表示幅の初期化
	# sは拡張文字列
	for xchar in s:
		if isHalfWidth(xchar[0][0]):	wid+=1	# 拡張文字の標準文字部で調べて半角なら+1
		else:	wid+=2	# 全角なら+2
	return wid

#
# SVS異体字選択子（vaiation selector）の判定
#
def isSVSVariationSelector(cp):
	# unicodeにおける異体字選択子のブロック内か？
		# 0xFE00-0xFE0F	Variation Selectors Supplement	字形選択子補助（SVS用）
	if  0xFE00<=cp  and cp <=0xFE0F:
		return True
	else:	return False

#
# IVS異体字選択子（vaiation selector）の判定
#
def isIVSVariationSelector(cp):
	# unicodeにおける異体字選択子のブロック内か？
		# 0xE0100-0xE01EF	Variation Selectors	字形選択子（IVS用）
	if  0xE0100<=cp and cp <=0xE01EF:
		return True
	else:	return False

#
# 文字列の拡張文字列化
#
# 文字列を拡張文字列に変換する	1文字が複数の符号位置であらわされている場合（代用対/結合文字/IVS/SVS）への対応
#	返値は(拡張文字,属性情報)のtuppleのlistでこれを「拡張文字列」とする
# 	このうち
#	拡張文字は
# 		UCS2のときはリスト
# 			[ 通常文字または文字列としての代用対 , 結合文字または異体字選択子（2バイトまたは代用対）または空文字 ]
# 		UCS4のときは文字列
# 			文字列（通常文字に結合文字または異体字選択子が付くことがある）
#	属性情報は属性値（整数）となる
#		属性は:
#		UCS: 通常のUnicode文字（Universal Coded Character Set）
#		CCS: 結合文字列（Combining Charactor Sequence）
#		SVS: 標準異体字列（Standard Variation Sequence）
#		IVS: 異体字列（Ideographic Variation Sequence）
#		に分類される
def toXstr(s):
	StringList=[]
	AttrList=[]	# 拡張文字列の属性リスト
	if isUCS2():
		surrogate_pair=False	# UCS2では代用対（surrogate pair）がありうる
		prevchar=""
		for c in s:
			cp=ord(c)	# code point
			# 代用対（[D800～DBFF]+[DC00～DFFF]のペア）の存在を考慮する
			if not surrogate_pair:	# 代用対の処理中でなければ
				if isHighSurrogate(cp):	# 代用対の前半部なら
					surrogate_pair=True	# surrogate pair starts
					HighSurrogate=c
					HighSurrogateCp=cp
					continue
				if isLowSurrogate(cp):	error("代用対の構成が無効です。")	# 代用対の後半部が単独で現れた
				elif isCombiningDiacriticalMark(cp):	# 合成可能文字なら
					if prevchar=="":	error("結合文字列の構成が無効です。")	# 空文字の次に合成可能文字が現われた
					StringList.append([prevchar,c])	# 先行文字と合成可能文字の組を追加（合成可能文字は第0面のみにある）
					AttrList.append(CCS)
					prevchar=""
				elif isSVSVariationSelector(cp):	# 異体字選択子なら（代用対ではないのでSVS用異体字選択子の可能性のみ検査する）
					if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
					StringList.append([prevchar,c])	# 先行文字とSVS用異体字選択子（2バイト）の組を追加
					AttrList.append(SVS)
					prevchar=""
				else:	# 次となる普通の文字がきたら先行文字を単独で追加
					if prevchar!="":
						StringList.append([prevchar,""])	# 先行文字と空文字の組を追加
						AttrList.append(UCS)
					prevchar=c	# 先行文字とする
			elif isLowSurrogate(cp):	# 代用対の処理中に代用対の後半部がきたら代用対の完成
				surrogate_pair=False	# surrogate pair ends
				sp=HighSurrogate+c	# 代用対を作る
				uni = 0x10000 + (HighSurrogateCp - 0xD800) * 0x400 + (cp - 0xDC00);	# 代用対をdecodeする
				if isIVSVariationSelector(uni):	# 代用対が異体字選択子なら（代用対なのでSVSてはなくIVSの可能性のみ検査する
					if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
					StringList.append([prevchar,sp])	# 先行文字とIVS用異体字選択子（4バイト）の組を追加
					AttrList.append(IVS)	# 代用対はIVS用異体字選択子
					prevchar=""
				else:	# 先行文字があって次に文字としての代用対が来た
					if prevchar!="":
						StringList.append([prevchar,""])	# 先行文字と空文字の組を追加
						AttrList.append(UCS)
					prevchar=sp	# 代用対を先行文字とする
			else:	error("代用対の構成が無効です。")	# 代用対の前半部の次に代用対後半部以外が現われた
		if surrogate_pair: 	error("代用対の構成が無効です。")	# 代用対の前半部で文字列の終端に達した
		if prevchar!="":
			StringList.append([prevchar,""])	# 最後の先行文字と空文字の組を追加
			AttrList.append(UCS)
	else:	# UCS4
		prevchar=""
		for c in s:
			cp=ord(c)	# code point
			if isCombiningDiacriticalMark(cp):	# 合成可能文字なら
				if prevchar=="":	error("結合文字列の構成が無効です。")	# 空文字の次に合成可能文字が現われた
				StringList.append(prevchar+c)	# 先行文字と合成可能文字の列を追加
				AttrList.append(CCS)
				prevchar=""
			elif isSVSVariationSelector(cp) or isIVSVariationSelector(cp):	# 異体字選択子なら
				if prevchar=="":	error("異体字列の構成が無効です。")	# 空文字の次に異体字選択子が現われた
				StringList.append(prevchar+c)	# 先行文字と異体字選択子（4バイト）の列を追加
				if isSVSVariationSelector(cp):
					AttrList.append(SVS)
				else:
					AttrList.append(IVS)
				prevchar=""
			else:
				if prevchar!="":
					StringList.append(prevchar)	# 次となる普通の文字がきたら先行文字を単独で追加
					AttrList.append(UCS)
				prevchar=c	# 先行文字とする
		if prevchar!="":
			StringList.append(prevchar)	# 最後の先行文字を追加
			AttrList.append(UCS)
	return list(zip(StringList, AttrList))	# (Xchar,Xattr)のtuppleのlistを返す

# XcharMatch 文字のゆるい一致検査
#
#	拡張文字同士で「ゆるい一致検査」をする
#		通常文字が与えられたときは拡張文字列に変換してから比較する
#		「拡張文字列」はtoXstr()が出力する文字単位のリストによる「文字列」
#		ふたつの文字列で同じ位置の文字の比較は
#			UCSとUCSのときは通常の文字比較で「一致/不一致」を決める
#			IVSとIVSのときは基底文字と異体字選択子の両方が同じなら「一致」とする
#			UCSとIVSのときはUCSと「IVSの基底文字」が同じなら（IVSの異体字選択子の値にかかわらず）「一致」（ゆるい一致）とする
#		これは、IVSに対して、その基底文字に等しいUCSは「異体字選択子による微小な字体差を包摂していて文字比較においてwild-characterのようになっている」ということによる
#		なお、UCSを表示したときに使用される字体は対応するIVSの異体字組があるときはfontシステムがその中からひとつを省略時字体（default glyph）として用いる
def XcharMatch(char1,char2):
	if type(char1)!=tuple:	# char1は通常文字
		Xchar1=toXstr(to_unicode(char1))[0]	# 拡張文字に変換
	else:
		Xchar1=char1
	if type(char2)!=tuple:	# char2は通常文字
		Xchar2=toXstr(to_unicode(char2))[0]	# 拡張文字に変換
	else:
		Xchar2=char2
	# LooseMatchでなかったら通常比較
	if not LooseMatch:
		return char1==char2
	# (拡張文字,属性)のtupleを分解
	char1=Xchar1[0]
	char2=Xchar2[0]
	attr1=Xchar1[1]
	attr2=Xchar2[1]
	if char1==char2:	# 拡張文字で一致のとき
		return True
	if char1[0]!=char2[0]:	# 拡張文字の基底文字部分が等しくないとき
		return False	# 両文字はここで不一致となった
	else:	# 文字の基底文字部分が等しいとき
		if (attr1==UCS and attr2==IVS) or (attr1==IVS and attr2==UCS):	# 基底文字部分が等しく片方はUCSでもう一方はIVS異体字選択子
			return True	# この拡張文字は一致←「片方はUCSでもう一方はIVS」は拡張部分が異なる場合の例外的一致
		else:	# 基底文字部分が等しく両方に結合文字/SVS異体字選択子/（異なる）IVS異体字選択子
		#　この段階では基底文字部分が等しく拡張部分が異なるままなので「例外」ではなく不一致となる
			return False	# 両文字は不一致

#
# XstrMatch 文字列のゆるい一致検査
#
#	拡張文字列同士で「ゆるい一致検査」をする
#		通常文字列が与えられたときは拡張文字列に変換してから比較する
#		「拡張文字列」はtoXstr()が出力する文字単位のリストによる「文字列」
#		ふたつの文字列で同じ位置の文字の比較はXcharMatch()で行なう
def XstrMatch(str1,str2):
	# 与えられた文字列が通常文字列のときは拡張文字列に変換しておく（文字列がUTF8ときときはunicodeへの変換もする）
	if type(str1)!=list:
		str1=toXstr(to_unicode(str1))
	if type(str2)!=list:
		str2=toXstr(to_unicode(str2))
	if str1==str2:	# 全体一致
		return True
	if len(str1)!=len(str2):	# 拡張文字列長（文字数）が異なる
		return False
	for i in range(0,len(str1)):
		if not XcharMatch(str1[i],str2[i]):
			return False
	return True	# 最後の文字まで一致した

# リストメソッドのindex()を拡張文字列を使用した「文字列のゆるい一致検査」で実現する代用関数（拡張文字列入力版）
def Xindex_in_list(Xstr1,Xstrlist):
	if type(Xstr1)!=list:
		Xstr1=toXstr(to_unicode(Xstr1))
	for i in range(0,len(Xstrlist)):	# 拡張文字列リストの前方からみていく
		Xstr2=Xstrlist[i]
		if Xstr2==None:
			continue
		if type(Xstr2)!=list:
			Xstr2=toXstr(to_unicode(Xstr2))
		if XstrMatch(Xstr1,Xstr2):
			return i	# Xstrlistのi番目でstrがみつかった
	#raise ValueError	# strlistにstrがみつからなかったらValueError例外を送出する
	return -1	# リストメソッドのindex()ではstrlistにstrがみつからなかったらValueError例外を送出するが代用関数では-1を返す

# リストに対するin演算子を拡張文字列を使用した「文字列のゆるい一致検査」で実現する代用関数（拡張文字列入力版）
def Xin_list(str,strlist):
	if Xindex_in_list(str,strlist)>=0:
		return True
	return False

#
# ngword ファイルの読み込み
# ngword指定ファイルの入力各行から空白で区切られた文字列群のうち最初の文字列の先頭文字を（拡張文字で）とりそれらの全行分のリストを返す
#
def read_ngword(fname):
	global firstline
	Xngword = []	# ngword文字の（拡張文字列による）list
	firstline=True
	for line in open_file(fname):
		line=preproc_line(line)	# 入力行の前処理
		l = [ x for x in re.split(' +', line) if x ]
		if l:
			# 先頭欄のl[0]についてunicode化しNFDtoNFC変換してから拡張文字列化しその先頭文字をngwordに積み上げる
			Xs=toXstr(to_unicode(NFDtoNFC(l[0])))	# NFDtoNFC()はPython2のときUTF8で値を返すのでunicode化が必要
			Xngword.append(Xs[0])	# 拡張文字列の先頭tupple=(先頭拡張文字（リスト/文字列）,拡張文字列の先頭拡張文字の属性（整数）)を積む
	return Xngword

#
# <check_file>
#
def read_check(n):
	global firstline
	letters = 'nNsSfFvVeEaAbBhHzZkKxXcCoOjJ-_'
	funcs = [
		chk_uint, chk_int, chk_ufloat, chk_float,
		chk_alpha, chk_ascii, chk_alnum, chk_halfwid,
		chk_fullwid, chk_fullkata, chk_valid, chk_checkdig,
		chk_upper, chk_addr, None
	]
	attr = []
	firstline=True
	for line in open_file(1):
		line=preproc_line(line)	# 入力行の前処理
		l = [ x for x in re.split(' +', line) if x ]
		if len(l) < 2:
			continue
		if not l[1][0] in letters:
			error("属性が正しくありません: '%s'", l[1])
		f = funcs[letters.index(l[1][0]) // 2]
		if f:
			if l[1][0].lower() == 'f' or l[1][0].lower() == 'v':	# 属性が小数または符号つき小数
				r = re.match(r'(\d*)\.?(\d*)$', l[1][1:])	# 桁数から整数部と小数部をとりだす
			else:
				r = re.match(r'(\d*)()$', l[1][1:])	# 桁数をとりだし小数部はnullとする
			if not r:
				error("属性が正しくありません: '%s'", l[1])
			w1 = int(r.group(1) or 0)	# 桁数の整数部の数値
			w2 = int(r.group(2) or 0)	# 桁数の小数部の数値
			l[0]=NFDtoNFC(l[0])	# tag名に対してNFDtoNFC変換をする
			attr += [ (l[0], l[1], w1, w2, f) ]	# attrは[タグ名 属性+桁数 桁数の整数部 桁数の小数部 検査関数]
	return attr

#
# 符号無し整数 nN
#
def chk_uint(attr, w1, w2, Xngword, data):
	if not re.match(r'\d+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 符号付き整数 sS
#
def chk_int(attr, w1, w2, Xngword, data):
	r = re.match(r'[+-]?(\d+)$', data)
	if not r:
		return True
	elif attr[0].isupper():
		return w1 and len(r.group(1)) != w1
	else:
		return w1 and len(r.group(1)) > w1

#
# 符号無し小数 fF
#
def chk_ufloat(attr, w1, w2, Xngword, data):
	r = re.match(r'(\d*)\.?(\d*)$', data)
	if not r or not r.group(1) + r.group(2):
		return True
	elif attr[0].isupper():
		return w1 and len(r.group(1)) != w1 \
			or w2 and len(r.group(2)) != w2
	else:
		return w1 and len(r.group(1)) > w1 \
			or w2 and len(r.group(2)) > w2

#
# 符号付き小数 vV
#
def chk_float(attr, w1, w2, Xngword, data):
	r = re.match(r'[+-]?(\d*)\.?(\d*)$', data)
	if not r or not r.group(1) + r.group(2):
		return True
	elif attr[0].isupper():
		return w1 and len(r.group(1)) != w1 \
			or w2 and len(r.group(2)) != w2
	else:
		return w1 and len(r.group(1)) > w1 \
			or w2 and len(r.group(2)) > w2

#
# 英字 eE
#
def chk_alpha(attr, w1, w2, Xngword, data):
	if not re.match(r'[a-zA-Z]+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 印刷可能文字(ASCII) aA
#
def chk_ascii(attr, w1, w2, Xngword, data):
	if not re.match(r'[\x21-\x7e]+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 英数字 bB
#
def chk_alnum(attr, w1, w2, Xngword, data):
	if not re.match(r'[a-zA-Z0-9]+$', data):
		return True
	elif attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 半角文字 hH
#
def chk_halfwid(attr, w1, w2, Xngword, data):
	data = to_unicode(data)
	Xdata=toXstr(data)
	for xchar in Xdata:
		if not isHalfWidth(xchar[0][0]): return True	# 全角文字が入っているのをみつけた
	if attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 全角文字 zZ
#
def chk_fullwid(attr, w1, w2, Xngword, data):
	Xdata=toXstr(to_unicode(data))
	if checkNgword(Xdata,Xngword): return True	# ngword検査
	for xchar in Xdata:
		if isHalfWidth(xchar[0][0]): return True	# 半角文字が入っているのをみつけた
	if attr[0].isupper():
		return w1 and strwidth_u(Xdata) != w1
	else:
		return w1 and strwidth_u(Xdata) > w1

#
# 全角カタカナ kK
#
def chk_fullkata(attr, w1, w2, Xngword, data):
	Xdata=toXstr(to_unicode(data))
	if checkNgword(Xdata,Xngword): return True	# ngword検査
	for xchar in Xdata:
		if len(xchar[0][0])>1: return True	# 全角カタカナはunicodeの第0面にあるのでUCS2での代用対なら該当しない
		cp=ord(xchar[0][0])	# 拡張文字の標準文字部分について符号位置（code point）をとる
		if  0x30a0<=cp and cp<=0x30ff or \
			0x31f0<=cp and cp<=0x31ff or \
			0x3000<=cp and cp<=0x303f: continue
			# 0x3099==cp or cp==0x309a: continue	# 結合文字はここにこない
			# U+30A0-30FF	Katakana 	片仮名（U+30fb～U+30ffは記号）（U+30a0ダブルハイフン「゠」はJISX0213-2004では記述記号）
			# U+31F0-31FF	Katakana Phonetic Extensions 	片仮名拡張（小書き片仮名）
			# U+3000-303F	CJK Symbols and Punctuation 	CJKの記号及び句読点
			# U+3099-309A	合成用濁点/合成用半濁点
		else:
			return True
	if attr[0].isupper():
		return w1 and strwidth_u(Xdata) != w1
	else:
		return w1 and strwidth_u(Xdata) > w1

#
# 有効文字	xX
#
def chk_valid(attr, w1, w2, Xngword, data):
	Xdata=toXstr(to_unicode(data))
	for xchar in Xdata:
		cp=xord(xchar[0][0])	# 拡張文字の標準文字部分について符号位置をとる
		if (0x0000<=cp and cp <=0x0020) or cp==0x007f:
			return True
	if checkNgword(Xdata,Xngword): return True	# ngword検査
	if attr[0].isupper():
		return w1 and strwidth_u(Xdata) != w1
	else:
		return w1 and strwidth_u(Xdata) > w1

#
# チェックデジット cC
#
def chk_checkdig(attr, w1, w2, Xngword, data):
	if not re.match(r'\d+$', data):
		return True
	chk = 0
	for x in data:
		chk += int(x)
	for i in range(1, len(data), 2):
		chk += 2 * int(data[i])
	return chk % 10 != 0

#
# 英大文字 oO
#
def chk_upper(attr, w1, w2, Xngword, data):
	if not re.match(r'[\x21-\x60\x7b-\x7e]+$', data):
		return True
	data = to_unicode(data)
	if attr[0].isupper():
		return w1 and len(data) != w1
	else:
		return w1 and len(data) > w1

#
# 住所用文字（全角文字＋半角英数）jJ
#
def chk_addr(attr, w1, w2, Xngword, data):
	data = to_unicode(data)
	if re.search(r'[\x00-\x20\x7f]', data):	# 制御文字ははねる
		return True
	Xdata=toXstr(data)
	if checkNgword(Xdata,Xngword): return True
	for xchar in Xdata:
		if isHalfWidth(xchar[0][0]):	# 半角文字が入っているのをみつけた
			if not re.match(r'[\x21-\x7e]+$', xchar[0][0]):	# 半角英数記号ではない
				return True
	if attr[0].isupper():
		return w1 and strwidth_u(Xdata) != w1
	else:
		return w1 and strwidth_u(Xdata) > w1

#
# 直接入力文字列の前処理
#
#  Python3においてコマンドラインからの直接入力文字列中にUnicode符号位置がU+FFFFを超えるコードがあると
#  Unicode文字に正しく変換されない場合があることへの対処をする
def utf2ucs(instr):
	outstr=""	# 出力文字列
	intlist=[]	# 作業用整数リスト
	for char in instr:
		if ord(char)>=0xdc00 and ord(char)<=0xdcff:	# 文字の符号位置がU+DCxxの範囲にあったら「UTF8もどき」
			intlist.append(ord(char)-0xdc00)	# 0xdc00のげたをはずして整数リストに入れる
		else:	# 通常文字がきたら
			if len(intlist)>0:	# ここまでに「UTF8もどき」列を変換した整数リストがあったら
				# bytesに変換してutf8からUCSへの変換をして出力文字列に追加
				outstr+= bytes(intlist).decode("utf_8")
				intlist=[]	# 整数リストを再初期化
			outstr+=char	# 新しくきた通常文字を出力文字列に追加
	# 「UTF8もどき」列を変換した整数リストが残っていたら
	# bytesに変換してutf8からUCSへの変換をして出力文字列に追加
	if len(intlist)>0:	outstr+= bytes(intlist).decode("utf_8")
	return outstr

# 改行符号（\r\n）の削除関数
def rm_eol(line):
	return line.rstrip("\r\n")	# 改行記号としてCRLF('\r\n')/CR('\r')/LF('\n')のすべてに対応する

# BOMの取得関数
def get_BOM():
	if Python3():	return chr(int("FEFF",16))	# U+FEFFはBOMのUnicode符号位置
	else:			return "\xEF\xBB\xBF"	# BOMは「EF BB BF」の3バイト

# BOMの削除関数
def rm_BOM(line):
	global firstline
	if not firstline: return line
	firstline=False
	if line.startswith(get_BOM()):	line=line[len(get_BOM()):]	# 行頭にBOMがあったらBOMを削除する
	return line

# ファイル入力行の前処理
def preproc_line(line):
	line=rm_eol(line)	# 行末の改行記号を削除する
	line=rm_BOM(line)	# ファイル先頭行の行頭にBOMがあったらこれを削除する
	return line

# Python3か判定する
def Python3():
	if sys.version_info >= (3, 0):
		return True
	else:
		return False

#
# utf8 変換
#
def to_utf8(s):
	try:
		return s.encode('utf-8')
	except:
		error("内部エラー UTF8への変換に失敗しました。")

#
# NFDtoNFC()のre.sub()から指定patternがみつかるごとに呼ばれるのでNFD/NFC変換をして返す
# 置換対象パターンはNFD文字:全角ひらがな/全角カタカナの清音に結合用濁点/結合用半濁点を連接したもの
# 置換先文字はNFC文字:全角ひらがな/全角カタカナの濁音/半濁音
#
def replace(matchobj):
	if Python3():	return unicodedata.normalize('NFC',matchobj.group(0))
	else:	return to_utf8(unicodedata.normalize('NFC',to_unicode(matchobj.group(0))))	# Python2ではutf8→unicdoe→utf8の変換をする

#
# 全角ひらがな/全角カタカナの濁音/半濁音のNFC化
#
def NFDtoNFC(str):
	# 全角ひらがな/全角カタカナの濁音/半濁音をNFCで統一して返す
	return re.sub(pattern,replace,str)

#
# メイン関数
#
if __name__ == '__main__':

	if len(sys.argv) <= 1 \
	 or sys.argv[1] == '--help' \
	 or sys.argv[1] == '--version':
		usage()

	#
	# NFD文字（清音+結合用濁点/結合用半濁点）検出のための正規表現パターンを準備
	#
	# 
	pattern=re.compile(_comb_pat)
	#
	# 拡張文字列の各文字ごとの属性識別用定数
	UCS,CCS,SVS,IVS=0,1,2,3
	# UCS: 通常のUnicode文字（Universal Coded Character Set）
	# CCS: 結合文字列（Combining Charactor Sequence）
	# SVS: 標準異体字列（Standard Variation Sequence）
	# IVS: 異体字列（Ideographical Variation Sequence）

	# 「ゆるい文字列一致」の指定
	LooseMatch=True	# 現在は固定

	#
	# オプション解析
	#
	through,Xngword = [], []
	Xfile_ngword = []
	while len(sys.argv) > 1:
		if sys.argv[1] == '--through':
			if len(sys.argv) <= 2:
				error("--through オプションの引数がありません。")
			through += [ sys.argv[2] ]
			del sys.argv[1:3]
		elif re.match(r'--through=(.+)', sys.argv[1]):	# --through=文字列
			r = re.match(r'--through=(.+)', sys.argv[1])
			through += [ r.group(1) ]	# --throughオプションが複数ある場合に合わせて積み上げる
			del sys.argv[1]
		elif sys.argv[1] == '--ngword':
			if len(sys.argv) <= 2:
				error("--ngword オプションの引数がありません。")
			Xfile_ngword=read_ngword(sys.argv[2])
			Xngword+=Xfile_ngword	# --ngwordオプションが複数ある場合に合わせてngwordを積み上げる
			del sys.argv[1:3]
		elif sys.argv[1][0] == '-' and len(sys.argv[1]) > 1:
			error("不明なオプション(%s)です。", sys.argv[1])
		else:
			break

	if not through:
		through = [ '_' ]

	if len(sys.argv) <= 1:
		usage()

	#
	# <check_file>
	#

	attr = read_check(1)

	#
	# メインループ
	#
	stat = 0
	if Python3():
		through=list(map(utf2ucs,through))	# Python3のときは直接指定の文字列に対して前処理をする
	else:
		through=list(map(to_unicode,through))	# Python2のときはutf8からunicodeへ変換

	# throughを拡張文字列化する
	if LooseMatch:
		Xthrough=[]
		for str in through:
			Xstr=toXstr(str)
			Xthrough.append(Xstr)

	firstline=True
	for line in open_file(2):
		line=preproc_line(line)	# 入力行の前処理
		line=NFDtoNFC(line)	# name_fileの行に対してNFDtoNFC変換をする
		l = re.findall(r' *([^ ]+) ?(.*)', line)	# formatは「0個以上の空白 空白以外の文字1個以上 空白0個または1個  0個以上の改行以外の文字」
		if LooseMatch:
			if not l or not l[0][1] or Xin_list(to_unicode(l[0][1]),Xthrough):	continue	# l[0][1]は<name_file>の値部
		else:
			if not l or not l[0][1] or to_unicode(l[0][1]) in through:	continue	# l[0][1]は<name_file>の値部
		for x in attr:	# check_fileによる検査指定のすべてについて
			#if re.match(x[0] + r'(_[+-]?\d+)?$', l[0][0]):	# l[0][0]は<name_file>の名前部でこれが<check_file>のtag名またはtag名+"_数値"に等しければ
			#上の文を拡張文字列を使用して代替した
			m=re.search(r'_[+-]?\d+$',l[0][0])	# <name_file>の名前部が「+"_数値」で終っていればその直前までの文字列をとりそうでなければ全体をとる
			if m:
				if m.start()==0:
					error("name_fileの名前部の構成が不正です")
				namestr=l[0][0][0:m.start()]
			else:
				namestr=l[0][0]
			if XstrMatch(toXstr(to_unicode(namestr)),toXstr(to_unicode(x[0]))):	# namestrと<check_file>のtag名が一致したら
				if x[-1](x[1], x[2], x[3], Xngword, l[0][1]):	# 検査関数(tag名,属性+桁数,桁数の整数部,桁数の小数部,name_fileの値部)を呼ぶ
					print('%s %s' % (l[0][0], x[1]))
					stat = 1
				break

	sys.exit(stat)
